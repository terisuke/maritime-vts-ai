# éŸ³å£°å…¥åŠ›å•é¡Œ è§£æ±ºæŒ‡ç¤ºæ›¸
**ä½œæˆæ—¥**: 2025å¹´8æœˆ14æ—¥  
**å„ªå…ˆåº¦**: ğŸ”´ CRITICAL

## ğŸ“Š å•é¡Œè¨ºæ–­çµæœ

### 1. æ ¹æœ¬åŸå› ã®ç‰¹å®š

#### ğŸ”´ Critical Issue: AudioWorkletã®ç«¶åˆçŠ¶æ…‹
**å ´æ‰€**: `frontend/src/hooks/useAudioRecorder.ts` 146-157è¡Œç›®

```javascript
// å•é¡Œã®ã‚³ãƒ¼ãƒ‰
setTimeout(() => {
  console.log('CRITICAL: setTimeout executing now, workletRef.current:', workletRef.current);
  if (workletRef.current) {
    console.log('AudioWorkletã«é–‹å§‹ã‚³ãƒãƒ³ãƒ‰ã‚’é€ä¿¡');
    workletRef.current.port.postMessage({ command: 'start' });
    console.log('CRITICAL: Start command sent to AudioWorklet');
  } else {
    console.error('CRITICAL: workletRef.current is null in setTimeout!');
  }
}, 500);
```

**å•é¡Œ**: 
- setTimeoutã®500msé…å»¶ä¸­ã«ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆãŒå†ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ã•ã‚Œã€refãŒå¤±ã‚ã‚Œã‚‹
- isRecordingãŒtrueã«è¨­å®šã•ã‚Œã¦ã‚‚ã€AudioWorkletãŒstartã‚³ãƒãƒ³ãƒ‰ã‚’å—ä¿¡ã—ãªã„

#### ğŸŸ¡ Issue 2: ãƒ¢ãƒ‡ãƒ«IDã®ä¸ä¸€è‡´
**å ´æ‰€**: è¤‡æ•°ã®ãƒ•ã‚¡ã‚¤ãƒ«
- è¨­å®š: `apac.anthropic.claude-sonnet-4-20250514-v1:0`
- å®Ÿéš›ã«å¿…è¦: APACãƒªãƒ¼ã‚¸ãƒ§ãƒ³ã®ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹

#### ğŸŸ  Issue 3: Transcribeã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†
**å ´æ‰€**: `backend/lambda/websocket-handler/shared/transcribe-processor.js`
- åŒæ™‚æ¥ç¶šæ•°ã®åˆ¶é™ï¼ˆ25ã‚¹ãƒˆãƒªãƒ¼ãƒ ï¼‰ã«ã™ãåˆ°é”
- ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ãŒä¸ååˆ†

## ğŸ› ï¸ å³åº§ã«å®Ÿæ–½ã™ã¹ãä¿®æ­£

### **Priority 1: AudioWorkletä¿®æ­£ï¼ˆ5åˆ†ï¼‰**

#### ä¿®æ­£1: useAudioRecorder.ts
```javascript
// frontend/src/hooks/useAudioRecorder.ts ã® 146è¡Œç›®ä»˜è¿‘ã‚’ä¿®æ­£

// ç¾åœ¨ã®ã‚³ãƒ¼ãƒ‰ï¼ˆå•é¡Œã‚ã‚Šï¼‰
setTimeout(() => {
  if (workletRef.current) {
    workletRef.current.port.postMessage({ command: 'start' });
  }
}, 500);

// ä¿®æ­£å¾Œã®ã‚³ãƒ¼ãƒ‰
// setTimeoutã‚’å‰Šé™¤ã—ã€å³åº§ã«é€ä¿¡
if (workletRef.current) {
  workletRef.current.port.postMessage({ command: 'start' });
  console.log('AudioWorklet start command sent immediately');
}
```

#### ä¿®æ­£2: audio-processor-worklet.js
```javascript
// frontend/public/audio-processor-worklet.js ã® constructor ã‚’ä¿®æ­£

constructor() {
  super();
  this.isRecording = false;
  this.processCallCount = 0;
  this.bufferSize = 4096; // ãƒãƒƒãƒ•ã‚¡ã‚µã‚¤ã‚ºã‚’è¿½åŠ 
  this.audioBuffer = []; // ãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°è¿½åŠ 
  
  console.log('AudioWorklet: Constructor called - AudioPCMProcessor initialized');
  
  this.port.onmessage = (event) => {
    console.log('AudioWorklet: Message received:', event.data);
    
    if (event.data.command === 'start') {
      this.isRecording = true;
      this.audioBuffer = []; // ãƒãƒƒãƒ•ã‚¡ã‚’ã‚¯ãƒªã‚¢
      console.log('AudioWorklet: Recording STARTED');
    } else if (event.data.command === 'stop') {
      this.isRecording = false;
      // æ®‹ã‚Šã®ãƒãƒƒãƒ•ã‚¡ã‚’é€ä¿¡
      if (this.audioBuffer.length > 0) {
        this.sendBufferedAudio();
      }
      console.log('AudioWorklet: Recording STOPPED');
    }
  };
}

// æ–°ã—ã„ãƒ¡ã‚½ãƒƒãƒ‰ã‚’è¿½åŠ 
sendBufferedAudio() {
  if (this.audioBuffer.length === 0) return;
  
  const pcmData = new Int16Array(this.audioBuffer);
  this.port.postMessage({
    type: 'audioData',
    data: pcmData
  });
  
  this.audioBuffer = [];
}

// process ãƒ¡ã‚½ãƒƒãƒ‰ã‚‚ä¿®æ­£
process(inputs, outputs, parameters) {
  if (!this.isRecording) {
    return true;
  }

  const input = inputs[0];
  if (input && input.length > 0) {
    const channelData = input[0];
    
    if (channelData && channelData.length > 0) {
      // PCMã«å¤‰æ›ã—ã¦ãƒãƒƒãƒ•ã‚¡ã«è¿½åŠ 
      for (let i = 0; i < channelData.length; i++) {
        const clampedValue = Math.max(-1, Math.min(1, channelData[i]));
        const pcmValue = Math.floor(clampedValue * 32767);
        this.audioBuffer.push(pcmValue);
      }
      
      // ãƒãƒƒãƒ•ã‚¡ãŒä¸€å®šã‚µã‚¤ã‚ºã«é”ã—ãŸã‚‰é€ä¿¡
      if (this.audioBuffer.length >= this.bufferSize) {
        this.sendBufferedAudio();
      }
    }
  }
  
  return true;
}
```

### **Priority 2: ç°¡æ˜“ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰å®Ÿè£…ï¼ˆ10åˆ†ï¼‰**

#### ãƒ‡ãƒãƒƒã‚°ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆä½œæˆ
```typescript
// frontend/src/components/debug/AudioDebugPanel.tsxï¼ˆæ–°è¦ä½œæˆï¼‰
import React from 'react';

interface AudioDebugPanelProps {
  isRecording: boolean;
  audioLevel: number;
  connectionStatus: string;
  lastTranscription?: string;
  errorLog?: string[];
}

const AudioDebugPanel: React.FC<AudioDebugPanelProps> = ({
  isRecording,
  audioLevel,
  connectionStatus,
  lastTranscription,
  errorLog = []
}) => {
  return (
    <div className="fixed bottom-4 right-4 bg-black bg-opacity-80 text-green-400 p-4 rounded-lg font-mono text-xs max-w-md">
      <h3 className="text-yellow-400 mb-2">ğŸ”§ Debug Panel</h3>
      <div className="space-y-1">
        <div>Recording: {isRecording ? 'ğŸ”´ ON' : 'âš« OFF'}</div>
        <div>Audio Level: {(audioLevel * 100).toFixed(1)}%</div>
        <div>WebSocket: {connectionStatus}</div>
        <div>Last Text: {lastTranscription || 'None'}</div>
      </div>
      {errorLog.length > 0 && (
        <div className="mt-2 text-red-400">
          <div>Errors:</div>
          {errorLog.slice(-3).map((err, i) => (
            <div key={i} className="text-xs">{err}</div>
          ))}
        </div>
      )}
    </div>
  );
};

export default AudioDebugPanel;
```

### **Priority 3: ãƒ†ã‚¹ãƒˆéŸ³å£°ç”Ÿæˆï¼ˆæ¤œè¨¼ç”¨ï¼‰**

#### ãƒ†ã‚¹ãƒˆãƒˆãƒ¼ãƒ³ç”Ÿæˆè¿½åŠ 
```javascript
// frontend/src/utils/testAudioGenerator.jsï¼ˆæ–°è¦ä½œæˆï¼‰
export function generateTestTone(frequencyHz = 440, durationMs = 1000) {
  const sampleRate = 16000;
  const samples = (sampleRate * durationMs) / 1000;
  const pcmData = new Int16Array(samples);
  
  for (let i = 0; i < samples; i++) {
    const t = i / sampleRate;
    const value = Math.sin(2 * Math.PI * frequencyHz * t);
    pcmData[i] = Math.floor(value * 32767);
  }
  
  return pcmData;
}

// AudioRecorderã«è¿½åŠ 
const sendTestTone = () => {
  const testData = generateTestTone(440, 500);
  const base64 = btoa(String.fromCharCode(...new Uint8Array(testData.buffer)));
  websocketService.send({
    action: 'audioData',
    payload: { audio: base64 },
    timestamp: new Date().toISOString()
  });
  console.log('Test tone sent:', testData.length, 'samples');
};
```

## ğŸš€ æ®µéšçš„å®Ÿè£…æ‰‹é †

### **Phase 1: ç·Šæ€¥ä¿®æ­£ï¼ˆä»Šã™ãï¼‰**

1. **AudioWorkletä¿®æ­£**
   ```bash
   cd frontend
   # useAudioRecorder.tsã® setTimeoutå‰Šé™¤
   # audio-processor-worklet.jsã®ãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°è¿½åŠ 
   npm run dev
   ```

2. **ãƒ†ã‚¹ãƒˆå®Ÿæ–½**
   ```bash
   # ãƒ–ãƒ©ã‚¦ã‚¶ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã§ç¢ºèª
   # 1. éŒ²éŸ³é–‹å§‹
   # 2. "AudioWorklet: Recording STARTED"ã‚’ç¢ºèª
   # 3. "AudioWorklet: Sending PCM data"ã‚’ç¢ºèª
   ```

### **Phase 2: ã‚µãƒ¼ãƒãƒ¼å´ç¢ºèªï¼ˆ30åˆ†ä»¥å†…ï¼‰**

1. **CloudWatch Logsã§ç¢ºèª**
   ```bash
   aws logs tail /aws/lambda/vts-websocket-handler --follow | grep -E "(audioData|Transcribe)"
   ```

2. **Lambdaé–¢æ•°ã®ç›´æ¥ãƒ†ã‚¹ãƒˆ**
   ```bash
   # test-audio.jsonä½œæˆ
   cat > test-audio.json << EOF
   {
     "requestContext": {
       "connectionId": "test-connection",
       "routeKey": "\$default"
     },
     "body": "{\"action\":\"startTranscription\",\"payload\":{\"languageCode\":\"ja-JP\"}}"
   }
   EOF
   
   # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
   aws lambda invoke \
     --function-name vts-websocket-handler \
     --payload file://test-audio.json \
     response.json
   ```

### **Phase 3: ä»£æ›¿æ¡ˆã¸ã®ç§»è¡Œæº–å‚™ï¼ˆ1æ™‚é–“å¾Œã«åˆ¤æ–­ï¼‰**

ã‚‚ã—ä¸Šè¨˜ã®ä¿®æ­£ã§è§£æ±ºã—ãªã„å ´åˆï¼š

#### **Option A: ã‚·ãƒ³ãƒ—ãƒ«ãªHTTP APIã¸ã®åˆ‡ã‚Šæ›¿ãˆ**

```javascript
// frontend/src/services/simpleTranscriptionService.js
class SimpleTranscriptionService {
  async sendAudioForTranscription(audioBlob) {
    const formData = new FormData();
    formData.append('audio', audioBlob, 'audio.wav');
    
    const response = await fetch('/api/transcribe', {
      method: 'POST',
      body: formData
    });
    
    return response.json();
  }
}
```

#### **Option B: AWS Amplify Predictionsã¸ã®ç§»è¡Œ**

```bash
# Amplifyã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
npm install @aws-amplify/predictions

# åˆæœŸåŒ–
amplify init
amplify add predictions
amplify push
```

## ğŸ“Š æˆåŠŸåŸºæº–

### 30åˆ†ä»¥å†…ã«ç¢ºèªã™ã¹ãé …ç›®

| ãƒã‚§ãƒƒã‚¯é …ç›® | æœŸå¾…ã•ã‚Œã‚‹çµæœ | ç¢ºèªæ–¹æ³• |
|------------|--------------|---------|
| AudioWorkletå‹•ä½œ | isRecording=true | ãƒ–ãƒ©ã‚¦ã‚¶ã‚³ãƒ³ã‚½ãƒ¼ãƒ« |
| PCMãƒ‡ãƒ¼ã‚¿é€ä¿¡ | chunksProcessed > 0 | CloudWatch Logs |
| Transcribeå¿œç­” | transcriptionResultå—ä¿¡ | WebSocketãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ |
| AIå¿œç­” | aiResponseå—ä¿¡ | ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰è¡¨ç¤º |

## ğŸ”´ æœ€çµ‚åˆ¤æ–­ãƒã‚¤ãƒ³ãƒˆ

**1æ™‚é–“å¾Œã®åˆ¤æ–­åŸºæº–**ï¼š
- âœ… éŸ³å£°ãƒ‡ãƒ¼ã‚¿ãŒTranscribeã«å±Šã„ã¦ã„ã‚‹ â†’ ç¾è¡Œã‚·ã‚¹ãƒ†ãƒ ç¶™ç¶š
- âŒ ã¾ã å‹•ä½œã—ãªã„ â†’ AWS Amplifyã¸ã®å³åº§ã®ç§»è¡Œ

## ğŸ“ ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³

ã‚‚ã—1æ™‚é–“ã§è§£æ±ºã—ãªã„å ´åˆï¼š

1. **AWS Amplify Predictionså®Ÿè£…ï¼ˆæ¨å¥¨ï¼‰**
   - å®Ÿè£…æ™‚é–“: 2-3æ™‚é–“
   - ä¿¡é ¼æ€§: é«˜
   - ã‚³ã‚¹ãƒˆ: åŒç­‰

2. **Amazon Chime SDKæ¡ç”¨**
   - å®Ÿè£…æ™‚é–“: 4-6æ™‚é–“
   - ä¿¡é ¼æ€§: æœ€é«˜
   - ã‚³ã‚¹ãƒˆ: ã‚„ã‚„é«˜

3. **å¤–éƒ¨ã‚µãƒ¼ãƒ“ã‚¹ï¼ˆAssemblyAIï¼‰**
   - å®Ÿè£…æ™‚é–“: 1-2æ™‚é–“
   - ä¿¡é ¼æ€§: é«˜
   - ã‚³ã‚¹ãƒˆ: æœˆé¡$99ã€œ

## ğŸ¯ é–‹ç™ºãƒãƒ¼ãƒ ã¸ã®æŒ‡ç¤º

**å³åº§ã«å®Ÿæ–½**ï¼š
1. AudioWorkletã®setTimeoutå‰Šé™¤ï¼ˆ5åˆ†ï¼‰
2. ãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°å®Ÿè£…ï¼ˆ10åˆ†ï¼‰
3. ãƒ‡ãƒãƒƒã‚°ãƒ‘ãƒãƒ«è¿½åŠ ï¼ˆ10åˆ†ï¼‰
4. ãƒ†ã‚¹ãƒˆå®Ÿæ–½ï¼ˆ15åˆ†ï¼‰

**40åˆ†å¾Œã«åˆ¤æ–­**ï¼š
- å‹•ä½œã™ã‚‹ â†’ ç¾è¡Œã‚·ã‚¹ãƒ†ãƒ ã§ç¶™ç¶š
- å‹•ä½œã—ãªã„ â†’ AWS Amplifyã¸ç§»è¡Œé–‹å§‹

**é‡è¦**: 2025å¹´8æœˆã®æœ€æ–°æƒ…å ±ã¨ã—ã¦ã€AWS Amplify PredictionsãŒæœ€ã‚‚å®‰å®šã—ãŸé¸æŠè‚¢ã§ã™ã€‚ç¾åœ¨ã®WebSocket + Transcribe Streamingã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯æŠ€è¡“çš„ã«è¤‡é›‘ã™ãã¾ã™ã€‚

---
**æ‰¿èªè€…**: ã‚·ã‚¹ãƒ†ãƒ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒˆ  
**å®Ÿæ–½æœŸé™**: 2025å¹´8æœˆ14æ—¥ 17:00ã¾ã§
